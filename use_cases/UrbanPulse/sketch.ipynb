{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rank', 'gridIndex', 'latLng', 'resolutions.ALL.isMaxima',\n",
      "       'resolutions.ALL.maxRank', 'resolutions.ALL.fnRank',\n",
      "       'resolutions.ALL.sigRank', 'resolutions.ALL.maxTime',\n",
      "       'resolutions.ALL.sigMaxTime', 'resolutions.ALL.fn',\n",
      "       'resolutions.ALL.scalars', 'resolutions.HOUR.isMaxima',\n",
      "       'resolutions.HOUR.maxRank', 'resolutions.HOUR.fnRank',\n",
      "       'resolutions.HOUR.sigRank', 'resolutions.HOUR.maxTime',\n",
      "       'resolutions.HOUR.sigMaxTime', 'resolutions.HOUR.fn',\n",
      "       'resolutions.HOUR.scalars', 'resolutions.DAYOFWEEK.isMaxima',\n",
      "       'resolutions.DAYOFWEEK.maxRank', 'resolutions.DAYOFWEEK.fnRank',\n",
      "       'resolutions.DAYOFWEEK.sigRank', 'resolutions.DAYOFWEEK.maxTime',\n",
      "       'resolutions.DAYOFWEEK.sigMaxTime', 'resolutions.DAYOFWEEK.fn',\n",
      "       'resolutions.DAYOFWEEK.scalars', 'resolutions.MONTH.isMaxima',\n",
      "       'resolutions.MONTH.maxRank', 'resolutions.MONTH.fnRank',\n",
      "       'resolutions.MONTH.sigRank', 'resolutions.MONTH.maxTime',\n",
      "       'resolutions.MONTH.sigMaxTime', 'resolutions.MONTH.fn',\n",
      "       'resolutions.MONTH.scalars'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Data loading (features)\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "json_features_file = open(\"flickr-features.json\")\n",
    "\n",
    "parsed_json_features = json.load(json_features_file)\n",
    "\n",
    "df_features = pd.json_normalize(parsed_json_features[\"features\"])\n",
    "\n",
    "df_features = df_features[[\"latLng\", \"rank\", \"resolutions.HOUR.fnRank\", \"resolutions.HOUR.sigRank\", \"resolutions.HOUR.maxRank\", \"resolutions.DAYOFWEEK.fnRank\", \"resolutions.DAYOFWEEK.sigRank\", \"resolutions.DAYOFWEEK.maxRank\", \"resolutions.MONTH.fnRank\", \"resolutions.MONTH.sigRank\", \"resolutions.MONTH.maxRank\"]]\n",
    "\n",
    "df_hour = df_features[[\"latLng\", \"rank\", \n",
    "    \"resolutions.HOUR.fnRank\", \"resolutions.HOUR.sigRank\", \"resolutions.HOUR.maxRank\"]].copy()\n",
    "\n",
    "df_dayofweek = df_features[[\"latLng\", \"rank\", \n",
    "    \"resolutions.DAYOFWEEK.fnRank\", \"resolutions.DAYOFWEEK.sigRank\", \"resolutions.DAYOFWEEK.maxRank\"]].copy()\n",
    "\n",
    "df_month = df_features[[\"latLng\", \"rank\", \n",
    "    \"resolutions.MONTH.fnRank\", \"resolutions.MONTH.sigRank\", \"resolutions.MONTH.maxRank\"]].copy()\n",
    "\n",
    "return df_hour, df_dayofweek, df_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation Analysis (HOUR)\n",
    "\n",
    "df_hour = arg[0]\n",
    "\n",
    "df_hour = df_hour.rename(columns={\"resolutions.HOUR.fnRank\": \"fnRank\", \"resolutions.HOUR.sigRank\": \"sigRank\", \"resolutions.HOUR.maxRank\": \"maxRank\"})\n",
    "\n",
    "df_hour = df_hour.dropna(subset=[\"fnRank\"])\n",
    "df_hour = df_hour.dropna(subset=[\"sigRank\"])\n",
    "df_hour = df_hour.dropna(subset=[\"maxRank\"])\n",
    "\n",
    "return df_hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation Analysis (DAYOFWEEK)\n",
    "\n",
    "df_dayofweek = arg[1]\n",
    "\n",
    "df_dayofweek = df_dayofweek.rename(columns={\"resolutions.DAYOFWEEK.fnRank\": \"fnRank\", \"resolutions.DAYOFWEEK.sigRank\": \"sigRank\", \"resolutions.DAYOFWEEK.maxRank\": \"maxRank\"})\n",
    "\n",
    "df_dayofweek = df_dayofweek.dropna(subset=[\"fnRank\"])\n",
    "df_dayofweek = df_dayofweek.dropna(subset=[\"sigRank\"])\n",
    "df_dayofweek = df_dayofweek.dropna(subset=[\"maxRank\"])\n",
    "\n",
    "return df_dayofweek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation Analysis (MONTH)\n",
    "\n",
    "df_month = arg[2]\n",
    "\n",
    "df_month = df_month.rename(columns={\"resolutions.MONTH.fnRank\": \"fnRank\", \"resolutions.MONTH.sigRank\": \"sigRank\", \"resolutions.MONTH.maxRank\": \"maxRank\"})\n",
    "\n",
    "df_month = df_month.dropna(subset=[\"fnRank\"])\n",
    "df_month = df_month.dropna(subset=[\"sigRank\"])\n",
    "df_month = df_month.dropna(subset=[\"maxRank\"])\n",
    "\n",
    "return df_month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation Analysis (computing rank - one for each period)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df_scatterplot = arg[[\"rank\", \"fnRank\", \"sigRank\", \"maxRank\"]]\n",
    "\n",
    "df_scatterplot[\"combinedRanks\"] = np.sqrt(\n",
    "    df_scatterplot[\"maxRank\"] ** 2 +\n",
    "    df_scatterplot[\"fnRank\"] ** 2 +\n",
    "    df_scatterplot[\"sigRank\"] ** 2\n",
    ")\n",
    "\n",
    "df_scatterplot['linked'] = df_scatterplot.index.to_series().apply(lambda x: [x])\n",
    "\n",
    "return df_scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pool (one for each period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vega-Lite (one for each period)\n",
    "\n",
    "{ \n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\", \n",
    "  \"title\": \"RANK (HOUR)\",\n",
    "  \"params\": [ {\"name\": \"clickSelect\", \"select\": \"interval\"} ], \n",
    "  \"mark\": { \"type\": \"point\", \"cursor\": \"pointer\" }, \n",
    "  \"encoding\": { \n",
    "    \"x\": {\"field\": \"combinedRanks\", \"type\": \"quantitative\"},\n",
    "    \"y\": {\"field\": \"rank\", \"type\": \"quantitative\"}, \n",
    "    \"fillOpacity\": { \n",
    "        \"condition\": {\"param\": \"clickSelect\", \"value\": 1}, \n",
    "        \"value\": 0.3 \n",
    "    }, \n",
    "    \"color\": { \n",
    "      \"field\": \"interacted\", \n",
    "      \"type\": \"nominal\", \n",
    "      \"condition\": {\n",
    "        \"test\": \"datum.interacted === '1'\", \"value\": \"red\", \"else\": \"blue\"} } \n",
    "  }, \n",
    "  \"config\": { \"scale\": { \"bandPaddingInner\": 0.2 } } \n",
    "} \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "json_features_file = open(\"flickr-features.json\")\n",
    "\n",
    "parsed_json_features = json.load(json_features_file)\n",
    "\n",
    "df_features = pd.json_normalize(parsed_json_features[\"features\"])\n",
    "\n",
    "df_features = df_features[[\"latLng\"]]\n",
    "\n",
    "return df_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformation (connected to df_features - convert latLng into points and create buffer)\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "df_points = arg\n",
    "\n",
    "df_points = df_points.explode(\"latLng\", ignore_index=True)\n",
    "\n",
    "df_points[\"geometry\"] = df_points[\"latLng\"].apply(lambda x: Point(x[1], x[0]))  # (lon, lat)\n",
    "\n",
    "gdf_points = gpd.GeoDataFrame(df_points, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "gdf_points = gdf_points.drop(columns=[\"latLng\"])\n",
    "\n",
    "gdf_points = gdf_points.to_crs(3857)\n",
    "\n",
    "gdf_points[\"geometry\"] = gdf_points[\"geometry\"].buffer(50)\n",
    "\n",
    "gdf_points[\"value\"] = 1\n",
    "\n",
    "gdf_points['linked'] = gdf_points.index.to_series().apply(lambda x: [x])\n",
    "\n",
    "gdf_points = gdf_points[[\"geometry\", \"value\", \"linked\"]]\n",
    "\n",
    "gdf_points = gdf_points.to_crs(3395)\n",
    "\n",
    "gdf_points.metadata = {\n",
    "    'name': 'pulse'\n",
    "}\n",
    "\n",
    "return gdf_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utk\n",
    "\n",
    "uc = utk.OSM.load([40.67187576076156, -74.0703927880446, 40.928446768674455, -73.8413807958497], layers=['parks'])\n",
    "\n",
    "#parks\n",
    "json_parks = uc.layers['json'][0]\n",
    "gdf_parks = uc.layers['gdf']['objects'][0]\n",
    "gdf_parks.metadata = {\n",
    " 'name': 'parks',\n",
    " 'style': 'parks'\n",
    "}\n",
    "\n",
    "return gdf_parks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "gdf_zip = gpd.read_file(\"nyc_zip.geojson\")\n",
    "\n",
    "gdf_zip = gdf_zip[[\"geometry\"]]\n",
    "\n",
    "gdf_zip = gdf_zip.to_crs(\"EPSG:4326\")\n",
    "\n",
    "min_lat, max_lat = 40.67187576076156, 40.928446768674455\n",
    "min_lon, max_lon = -74.0703927880446, -73.8413807958497\n",
    "bbox = box(min_lon, min_lat, max_lon, max_lat)\n",
    "bbox_gdf = gpd.GeoDataFrame(geometry=[bbox], crs=\"EPSG:4326\")\n",
    "\n",
    "gdf_zip = gdf_zip[gdf_zip.within(bbox_gdf.iloc[0].geometry)]\n",
    "\n",
    "gdf_zip = gdf_zip.to_crs(\"3395\")\n",
    "\n",
    "gdf_zip.metadata = {\n",
    "    'name': 'zip'\n",
    "}\n",
    "\n",
    "return gdf_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utk\n",
    "\n",
    "uc = utk.OSM.load([40.67187576076156, -74.0703927880446, 40.928446768674455, -73.8413807958497], layers=['water'])\n",
    "\n",
    "json_water = uc.layers['json'][0]\n",
    "gdf_water = uc.layers['gdf']['objects'][0]\n",
    "gdf_water.metadata = {\n",
    " 'name': 'water',\n",
    " 'style': 'water'\n",
    "}\n",
    "\n",
    "return gdf_water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge (gdf_water, gdf_zip, gdf_parks, data pool)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curio-backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
