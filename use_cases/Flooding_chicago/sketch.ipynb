{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation Analysis\n",
    "\n",
    "from synxflow import IO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from pyproj import Transformer\n",
    "\n",
    "DEM = IO.Raster('./flooding_data/output.tif')\n",
    "rain_mask = IO.Raster(\"./flooding_data/rain_mask.tif\")\n",
    "rain_source = pd.read_csv(\"./flooding_data/alternate_rain_source.csv\", header=None)\n",
    "rain_source_np = rain_source.to_numpy()\n",
    "\n",
    "ngpus = 1\n",
    "case_folder = os.path.join('./', 'flooding_data') # define a case folder in the current directory\n",
    "case_input = IO.InputModel(DEM, num_of_sections=ngpus, case_folder=case_folder)\n",
    "case_input.set_initial_condition('h0', 0.0)\n",
    "case_input.set_rainfall(rain_mask=rain_mask, rain_source=rain_source_np)\n",
    "case_input.set_grid_parameter(manning=0.035)\n",
    "case_input.set_runtime([0, 3600, 60, 60])\n",
    "case_input.write_input_files()\n",
    "\n",
    "from synxflow import flood\n",
    "if case_input.num_of_sections > 1:\n",
    "    flood.run_mgpus(case_input.get_case_folder())\n",
    "else:\n",
    "    flood.run(case_input.get_case_folder())\n",
    "\n",
    "current_path = os.getcwd()\n",
    "\n",
    "case_input_copy = case_input\n",
    "case_input_copy.set_case_folder(current_path)\n",
    "\n",
    "case_output = IO.OutputModel(input_obj = case_input_copy)\n",
    "\n",
    "gauges_pos, times, values_gauge = case_output.read_gauges_file(file_tag = 'h')\n",
    "\n",
    "transformer_utm_to_mercator = Transformer.from_crs(\"epsg:26916\", \"epsg:3857\", always_xy=True)\n",
    "transformer_mercator_to_latlon = Transformer.from_crs(\"epsg:3857\", \"epsg:4326\", always_xy=True)\n",
    "\n",
    "coordinates_list = []\n",
    "\n",
    "max_depth = case_output.read_grid_file(file_tag='h_max_3600')\n",
    "\n",
    "with rasterio.open(\"./output.tif\") as src:\n",
    "\n",
    "    width = src.width\n",
    "    height = src.height\n",
    "\n",
    "    transform = src.transform\n",
    "\n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            lon_utm, lat_utm = transform * (col, row)\n",
    "\n",
    "            lon_mercator, lat_mercator = transformer_utm_to_mercator.transform(lon_utm, lat_utm)\n",
    "\n",
    "            lon_lat, lat_lat = transformer_mercator_to_latlon.transform(lon_mercator, lat_mercator)\n",
    "\n",
    "            coordinates_list.append(Point(lon_lat, lat_lat))\n",
    "\n",
    "values = max_depth.array.flatten()  # Flatten raster values\n",
    "values = values.tolist()\n",
    "\n",
    "while len(values) < len(coordinates_list):\n",
    "    values.append(0)\n",
    "\n",
    "gdf_flood = gpd.GeoDataFrame({'value': values, 'geometry': coordinates_list}, geometry=\"geometry\", crs=\"4326\")\n",
    "\n",
    "gdf_flood = gdf_flood.dropna(subset=[\"value\"])\n",
    "\n",
    "return times.tolist(), values_gauge.tolist(), gdf_flood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # xv, yv = max_depth.to_points()  # Get coordinate grids\n",
    "\n",
    "# # max_depth.header\n",
    "# # {'ncols': 337,\n",
    "# #  'nrows': 393,\n",
    "# #  'xllcorner': 428427.7933215814,\n",
    "# #  'yllcorner': 4602438.36674475,\n",
    "# #  'cellsize': 26.757362390421342,\n",
    "# #  'NODATA_value': -9999}\n",
    "\n",
    "# import geopandas as gpd\n",
    "# import pandas as pd\n",
    "# from shapely.geometry import Point\n",
    "# import numpy as np\n",
    "# import rasterio\n",
    "# import os\n",
    "\n",
    "# # Read the raster\n",
    "# with rasterio.open(\"./output/h_max_3600.asc\") as src:\n",
    "#     data = src.read(1)  # Read raster values\n",
    "#     transform = src.transform  # Get transform\n",
    "\n",
    "# # Get non-NODATA values\n",
    "# rows, cols = np.where(data != -9999)  # Find valid pixels\n",
    "# values = data[rows, cols]  # Get corresponding values\n",
    "\n",
    "# # Convert row, col to coordinates\n",
    "# x_coords, y_coords = rasterio.transform.xy(transform, rows, cols)\n",
    "\n",
    "# # Create a GeoDataFrame\n",
    "# df = pd.DataFrame({\"x\": x_coords, \"y\": y_coords, \"value\": values})\n",
    "# gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.x, df.y))\n",
    "\n",
    "# # print(gdf.head())  # Show some points\n",
    "\n",
    "# # print(gdf.crs)\n",
    "\n",
    "# gdf = gdf.set_crs(26916)\n",
    "# # 32616\n",
    "# gdf = gdf.to_crs(4326)\n",
    "\n",
    "# gdf.plot()\n",
    "\n",
    "# # Save as a GeoJSON or Shapefile\n",
    "# # gdf.to_file(\"output.geojson\", driver=\"GeoJSON\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rasterio\n",
    "# from pyproj import Transformer\n",
    "\n",
    "# transformer_utm_to_mercator = Transformer.from_crs(\"epsg:26916\", \"epsg:3857\", always_xy=True)\n",
    "# transformer_mercator_to_latlon = Transformer.from_crs(\"epsg:3857\", \"epsg:4326\", always_xy=True)\n",
    "\n",
    "# coordinates_list = []\n",
    "\n",
    "# with rasterio.open(\"./output/h_max_3600.asc\") as src:\n",
    "\n",
    "#     width = src.width\n",
    "#     height = src.height\n",
    "\n",
    "#     transform = src.transform\n",
    "\n",
    "#     for row in range(height):\n",
    "#         for col in range(width):\n",
    "#             lon_utm, lat_utm = transform * (col, row)\n",
    "\n",
    "#             lon_mercator, lat_mercator = transformer_utm_to_mercator.transform(lon_utm, lat_utm)\n",
    "\n",
    "#             lon_lat, lat_lat = transformer_mercator_to_latlon.transform(lon_mercator, lat_mercator)\n",
    "\n",
    "#             coordinates_list.append((lon_lat, lat_lat))\n",
    "\n",
    "# print(coordinates_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "times = arg[0]\n",
    "values = arg[1]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(len(times)):\n",
    "    data.append({\n",
    "        'time': times[i],\n",
    "        'depth': values[i][0],\n",
    "        'label': 'downstream'\n",
    "    })\n",
    "    data.append({\n",
    "        'time': times[i],\n",
    "        'depth': values[i][1],\n",
    "        'label': 'upstream'\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation Analysis (run flood and ouput)\n",
    "\n",
    "# from synxflow import IO\n",
    "\n",
    "# ngpus = 1\n",
    "# case_folder = \"./data/flood_case\"\n",
    "\n",
    "# from synxflow import flood\n",
    "# if ngpus > 1:\n",
    "#     flood.run_mgpus(case_folder)\n",
    "# else:\n",
    "#     flood.run(case_folder)\n",
    "\n",
    "# case_output = IO.OutputModel(input_obj = case_input)\n",
    "\n",
    "# gauges_pos, times, values = case_output.read_gauges_file(file_tag = 'h')\n",
    "\n",
    "# return times, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vega-Lite (connected to Computation Analysis - line chart with times and values)\n",
    "\n",
    "{\n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "  \"description\": \"Depth over time for downstream and upstream\",\n",
    "  \"width\": 600,\n",
    "  \"height\": 400,\n",
    "  \"mark\": {\n",
    "    \"type\": \"line\",\n",
    "    \"interpolate\": \"monotone\"\n",
    "  },\n",
    "  \"encoding\": {\n",
    "    \"x\": {\n",
    "      \"field\": \"time\",\n",
    "      \"type\": \"quantitative\",\n",
    "      \"title\": \"Time (s)\"\n",
    "    },\n",
    "    \"y\": {\n",
    "      \"field\": \"depth\",\n",
    "      \"type\": \"quantitative\",\n",
    "      \"title\": \"Depth (m)\"\n",
    "    },\n",
    "    \"color\": {\n",
    "      \"field\": \"label\",\n",
    "      \"type\": \"nominal\",\n",
    "      \"title\": \"Measurement\",\n",
    "      \"scale\": {\n",
    "        \"domain\": [\"downstream\", \"upstream\"],\n",
    "        \"range\": [\"#1f77b4\", \"#ff7f0e\"]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation Analysis (flooding raster)\n",
    "\n",
    "# import geopandas as gpd\n",
    "\n",
    "# gdf = arg[2]\n",
    "\n",
    "# gdf = gdf.set_crs('EPSG:27700')\n",
    "# gdf = gdf.to_crs(3857)\n",
    "\n",
    "# gdf[\"geometry\"] = gdf[\"geometry\"].buffer(50)\n",
    "\n",
    "# gdf = gdf.set_geometry('geometry')\n",
    "\n",
    "# gdf = gdf.to_crs(3395)\n",
    "\n",
    "# gdf.metadata = {\n",
    "#     'name': 'resulting'\n",
    "# }\n",
    "\n",
    "# return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformation\n",
    "\n",
    "# import geopandas as gpd\n",
    "\n",
    "# max_depth = case_output.read_grid_file(file_tag='h_max_7200')\n",
    "\n",
    "# # ========== Solution 1 ================\n",
    "# # src_epsg=27700 #EPSG code of the coordinate reference system of the original dataset, default is 27700 for BNG\n",
    "\n",
    "# # if not hasattr(max_depth, 'meta'):\n",
    "# #     max_depth.get_meta(src_epsg)\n",
    "\n",
    "# # meta = max_depth.meta  # dictionary\n",
    "# # array_data = max_depth.array.copy()  # Ensure a copy to avoid modifying the original\n",
    "# # nomask = np.isnan(array_data)\n",
    "# # array_data[nomask] = meta['nodata']\n",
    "# # ======================================\n",
    "\n",
    "# latLng = max_depth.to_points()\n",
    "\n",
    "# xv, yv = max_depth.to_points()  # Get coordinate grids\n",
    "# values = max_depth.array.flatten()  # Flatten raster values\n",
    "# points = [Point(x, y) for x, y in zip(xv.flatten(), yv.flatten())]  # Create Point geometries\n",
    "\n",
    "# gdf = gpd.GeoDataFrame({'value': values, 'geometry': points}, crs=f\"EPSG:27700\")\n",
    "\n",
    "# return gdf\n",
    "\n",
    "# # gdf.plot(column=\"value\", cmap=\"plasma\", legend=True, markersize=10)\n",
    "\n",
    "# # .get_summary() - Get information summary of the object\n",
    "# # .set_crs()\n",
    "# # .to_points() - Get X and Y coordinates of all raster cells\n",
    "# # .write_asc(output_file) - Write raster as asc format file\n",
    "# # .write() - Export to a file, tif, asc, txt, or gz\n",
    "# # .write_tif() - Convert to a resterio dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load box\n",
    "import utk\n",
    "\n",
    "# uc = utk.OSM.load([42.336844, -71.113459, 42.345559, -71.099216], layers=[{'name':'buildings', 'args': {'sizeCells': 5}}, {'name':'surface', 'args': {'sizeCells': 5}}, 'parks'])\n",
    "uc = utk.OSM.load([41.57124999999999, -87.85847222222222, 41.665138888888876, -87.75125], layers=['surface'])\n",
    "\n",
    "# # buildings\n",
    "# gdf_buildings = uc.layers['gdf']['sections'][0]\n",
    "# gdf_buildings['thematic'] = 0.5\n",
    "# gdf_buildings.metadata = {\n",
    "#  'name': 'buildings'\n",
    "# }\n",
    "\n",
    "#surface\n",
    "json_surface = uc.layers['json'][0]\n",
    "gdf_surface = uc.layers['gdf']['objects'][0]\n",
    "gdf_surface.metadata = {\n",
    " 'name': 'surface'\n",
    "}\n",
    "\n",
    "# #parks\n",
    "# json_parks = uc.layers['json'][2]\n",
    "# gdf_parks = uc.layers['gdf']['objects'][2]\n",
    "# gdf_parks.metadata = {\n",
    "#  'name': 'parks'\n",
    "# }\n",
    "\n",
    "# return gdf_buildings, gdf_surface, gdf_parks\n",
    "return gdf_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data tranformation (connected to gdf_surface)\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import numpy as np\n",
    "\n",
    "gdf_surface = arg\n",
    "\n",
    "minx, miny, maxx, maxy = gdf_surface.geometry.total_bounds\n",
    "cell_size = 100\n",
    "\n",
    "grid_cells = []\n",
    "for x0 in np.arange(minx, maxx, cell_size):\n",
    "    for y0 in np.arange(miny, maxy, cell_size):\n",
    "        # 1st cell boundary\n",
    "        x1 = x0 + cell_size\n",
    "        y1 = y0 + cell_size\n",
    "        grid_cells.append(Polygon([(x0, y0), (x1, y0), (x1, y1), (x0, y1)]))\n",
    "\n",
    "grid_gdf = gpd.GeoDataFrame(geometry=grid_cells, crs=\"EPSG:3395\")\n",
    "\n",
    "grid_gdf = grid_gdf.reset_index(drop=True)\n",
    "\n",
    "grid_gdf.metadata = {\n",
    "    'name': 'grid'\n",
    "}\n",
    "\n",
    "return grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation analysis (color grid with flood values)\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "gdf_flood = arg[0]\n",
    "grid_gdf = arg[1]\n",
    "\n",
    "gdf_flood = gdf_flood.set_crs(4326)\n",
    "grid_gdf = grid_gdf.set_crs(3395)\n",
    "\n",
    "gdf_flood = gdf_flood.to_crs(3395)\n",
    "\n",
    "joined = gpd.sjoin(grid_gdf, gdf_flood, how='left', predicate='contains')\n",
    "\n",
    "grid_gdf['average_value'] = joined.groupby(joined.index)['value'].mean()\n",
    "\n",
    "grid_gdf = grid_gdf[[\"geometry\", \"average_value\"]]\n",
    "grid_gdf = grid_gdf.rename(columns={\"average_value\": \"value\"})\n",
    "\n",
    "grid_gdf = grid_gdf.dropna(subset=[\"value\"])\n",
    "\n",
    "grid_gdf.metadata = {\n",
    "    'name': 'ground'\n",
    "}\n",
    "\n",
    "return grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gdf.plot(column=\"value\", cmap=\"viridis\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curio-sandbox-frontend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
