{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation Analysis\n",
    "\n",
    "from synxflow import IO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from pyproj import Transformer\n",
    "\n",
    "DEM = IO.Raster('./flooding_data/output.tif')\n",
    "rain_mask = IO.Raster(\"./flooding_data/rain_mask.tif\")\n",
    "rain_source = pd.read_csv(\"./flooding_data/alternate_rain_source.csv\", header=None)\n",
    "rain_source_np = rain_source.to_numpy()\n",
    "\n",
    "ngpus = 1\n",
    "case_folder = os.path.join('./', 'flooding_data') # define a case folder in the current directory\n",
    "case_input = IO.InputModel(DEM, num_of_sections=ngpus, case_folder=case_folder)\n",
    "case_input.set_initial_condition('h0', 0.0)\n",
    "case_input.set_rainfall(rain_mask=rain_mask, rain_source=rain_source_np)\n",
    "case_input.set_grid_parameter(manning=0.035)\n",
    "case_input.set_runtime([0, 3600, 60, 60])\n",
    "case_input.write_input_files()\n",
    "\n",
    "from synxflow import flood\n",
    "if case_input.num_of_sections > 1:\n",
    "    flood.run_mgpus(case_input.get_case_folder())\n",
    "else:\n",
    "    flood.run(case_input.get_case_folder())\n",
    "\n",
    "current_path = os.getcwd()\n",
    "\n",
    "case_input_copy = case_input\n",
    "case_input_copy.set_case_folder(current_path)\n",
    "\n",
    "case_output = IO.OutputModel(input_obj = case_input_copy)\n",
    "\n",
    "gauges_pos, times, values_gauge = case_output.read_gauges_file(file_tag = 'h')\n",
    "\n",
    "transformer_utm_to_mercator = Transformer.from_crs(\"epsg:26916\", \"epsg:3857\", always_xy=True)\n",
    "transformer_mercator_to_latlon = Transformer.from_crs(\"epsg:3857\", \"epsg:4326\", always_xy=True)\n",
    "\n",
    "coordinates_list = []\n",
    "\n",
    "max_depth = case_output.read_grid_file(file_tag='h_max_3600')\n",
    "\n",
    "with rasterio.open(\"./output.tif\") as src:\n",
    "\n",
    "    width = src.width\n",
    "    height = src.height\n",
    "\n",
    "    transform = src.transform\n",
    "\n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            lon_utm, lat_utm = transform * (col, row)\n",
    "\n",
    "            lon_mercator, lat_mercator = transformer_utm_to_mercator.transform(lon_utm, lat_utm)\n",
    "\n",
    "            lon_lat, lat_lat = transformer_mercator_to_latlon.transform(lon_mercator, lat_mercator)\n",
    "\n",
    "            coordinates_list.append(Point(lon_lat, lat_lat))\n",
    "\n",
    "values = max_depth.array.flatten()  # Flatten raster values\n",
    "values = values.tolist()\n",
    "\n",
    "while len(values) < len(coordinates_list):\n",
    "    values.append(0)\n",
    "\n",
    "gdf_flood = gpd.GeoDataFrame({'value': values, 'geometry': coordinates_list}, geometry=\"geometry\", crs=\"4326\")\n",
    "\n",
    "gdf_flood = gdf_flood.dropna(subset=[\"value\"])\n",
    "\n",
    "return times.tolist(), values_gauge.tolist(), gdf_flood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # xv, yv = max_depth.to_points()  # Get coordinate grids\n",
    "\n",
    "# # max_depth.header\n",
    "# # {'ncols': 337,\n",
    "# #  'nrows': 393,\n",
    "# #  'xllcorner': 428427.7933215814,\n",
    "# #  'yllcorner': 4602438.36674475,\n",
    "# #  'cellsize': 26.757362390421342,\n",
    "# #  'NODATA_value': -9999}\n",
    "\n",
    "# import geopandas as gpd\n",
    "# import pandas as pd\n",
    "# from shapely.geometry import Point\n",
    "# import numpy as np\n",
    "# import rasterio\n",
    "# import os\n",
    "\n",
    "# # Read the raster\n",
    "# with rasterio.open(\"./output/h_max_3600.asc\") as src:\n",
    "#     data = src.read(1)  # Read raster values\n",
    "#     transform = src.transform  # Get transform\n",
    "\n",
    "# # Get non-NODATA values\n",
    "# rows, cols = np.where(data != -9999)  # Find valid pixels\n",
    "# values = data[rows, cols]  # Get corresponding values\n",
    "\n",
    "# # Convert row, col to coordinates\n",
    "# x_coords, y_coords = rasterio.transform.xy(transform, rows, cols)\n",
    "\n",
    "# # Create a GeoDataFrame\n",
    "# df = pd.DataFrame({\"x\": x_coords, \"y\": y_coords, \"value\": values})\n",
    "# gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.x, df.y))\n",
    "\n",
    "# # print(gdf.head())  # Show some points\n",
    "\n",
    "# # print(gdf.crs)\n",
    "\n",
    "# gdf = gdf.set_crs(26916)\n",
    "# # 32616\n",
    "# gdf = gdf.to_crs(4326)\n",
    "\n",
    "# gdf.plot()\n",
    "\n",
    "# # Save as a GeoJSON or Shapefile\n",
    "# # gdf.to_file(\"output.geojson\", driver=\"GeoJSON\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rasterio\n",
    "# from pyproj import Transformer\n",
    "\n",
    "# transformer_utm_to_mercator = Transformer.from_crs(\"epsg:26916\", \"epsg:3857\", always_xy=True)\n",
    "# transformer_mercator_to_latlon = Transformer.from_crs(\"epsg:3857\", \"epsg:4326\", always_xy=True)\n",
    "\n",
    "# coordinates_list = []\n",
    "\n",
    "# with rasterio.open(\"./output/h_max_3600.asc\") as src:\n",
    "\n",
    "#     width = src.width\n",
    "#     height = src.height\n",
    "\n",
    "#     transform = src.transform\n",
    "\n",
    "#     for row in range(height):\n",
    "#         for col in range(width):\n",
    "#             lon_utm, lat_utm = transform * (col, row)\n",
    "\n",
    "#             lon_mercator, lat_mercator = transformer_utm_to_mercator.transform(lon_utm, lat_utm)\n",
    "\n",
    "#             lon_lat, lat_lat = transformer_mercator_to_latlon.transform(lon_mercator, lat_mercator)\n",
    "\n",
    "#             coordinates_list.append((lon_lat, lat_lat))\n",
    "\n",
    "# print(coordinates_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "times = arg[0]\n",
    "values = arg[1]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(len(times)):\n",
    "    data.append({\n",
    "        'time': times[i],\n",
    "        'depth': values[i][0],\n",
    "        'label': 'downstream'\n",
    "    })\n",
    "    data.append({\n",
    "        'time': times[i],\n",
    "        'depth': values[i][1],\n",
    "        'label': 'upstream'\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation Analysis (run flood and ouput)\n",
    "\n",
    "# from synxflow import IO\n",
    "\n",
    "# ngpus = 1\n",
    "# case_folder = \"./data/flood_case\"\n",
    "\n",
    "# from synxflow import flood\n",
    "# if ngpus > 1:\n",
    "#     flood.run_mgpus(case_folder)\n",
    "# else:\n",
    "#     flood.run(case_folder)\n",
    "\n",
    "# case_output = IO.OutputModel(input_obj = case_input)\n",
    "\n",
    "# gauges_pos, times, values = case_output.read_gauges_file(file_tag = 'h')\n",
    "\n",
    "# return times, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vega-Lite (connected to Computation Analysis - line chart with times and values)\n",
    "\n",
    "{\n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "  \"description\": \"Depth over time for downstream and upstream\",\n",
    "  \"width\": 600,\n",
    "  \"height\": 400,\n",
    "  \"mark\": {\n",
    "    \"type\": \"line\",\n",
    "    \"interpolate\": \"monotone\"\n",
    "  },\n",
    "  \"encoding\": {\n",
    "    \"x\": {\n",
    "      \"field\": \"time\",\n",
    "      \"type\": \"quantitative\",\n",
    "      \"title\": \"Time (s)\"\n",
    "    },\n",
    "    \"y\": {\n",
    "      \"field\": \"depth\",\n",
    "      \"type\": \"quantitative\",\n",
    "      \"title\": \"Depth (m)\"\n",
    "    },\n",
    "    \"color\": {\n",
    "      \"field\": \"label\",\n",
    "      \"type\": \"nominal\",\n",
    "      \"title\": \"Measurement\",\n",
    "      \"scale\": {\n",
    "        \"domain\": [\"downstream\", \"upstream\"],\n",
    "        \"range\": [\"#1f77b4\", \"#ff7f0e\"]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load box\n",
    "import utk\n",
    "\n",
    "uc = utk.OSM.load([41.60883899452448, -87.84803061888353, 41.62549084306544, -87.81950563201464], layers=[{'name':'buildings', 'args': {'sizeCells': -1}}])\n",
    "\n",
    "# buildings\n",
    "gdf_buildings = uc.layers['gdf']['sections'][0]\n",
    "gdf_buildings.metadata = {\n",
    " 'name': 'buildings'\n",
    "}\n",
    "\n",
    "return gdf_buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load box\n",
    "import utk\n",
    "\n",
    "uc = utk.OSM.load([41.57124999999999, -87.85847222222222, 41.665138888888876, -87.75125], layers=['surface'])\n",
    "\n",
    "#surface\n",
    "json_surface = uc.layers['json'][0]\n",
    "gdf_surface = uc.layers['gdf']['objects'][0]\n",
    "gdf_surface.metadata = {\n",
    " 'name': 'surface'\n",
    "}\n",
    "\n",
    "return gdf_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data tranformation (connected to gdf_surface)\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import numpy as np\n",
    "\n",
    "gdf_surface = arg\n",
    "\n",
    "minx, miny, maxx, maxy = gdf_surface.geometry.total_bounds\n",
    "cell_size = 50\n",
    "\n",
    "grid_cells = []\n",
    "for x0 in np.arange(minx, maxx, cell_size):\n",
    "    for y0 in np.arange(miny, maxy, cell_size):\n",
    "        # 1st cell boundary\n",
    "        x1 = x0 + cell_size\n",
    "        y1 = y0 + cell_size\n",
    "        grid_cells.append(Polygon([(x0, y0), (x1, y0), (x1, y1), (x0, y1)]))\n",
    "\n",
    "grid_gdf = gpd.GeoDataFrame(geometry=grid_cells, crs=\"EPSG:3395\")\n",
    "\n",
    "grid_gdf = grid_gdf.reset_index(drop=True)\n",
    "\n",
    "grid_gdf.metadata = {\n",
    "    'name': 'grid'\n",
    "}\n",
    "\n",
    "return grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge grid_flood and grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation analysis (color grid with flood values)\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "gdf_flood = arg[0]\n",
    "grid_gdf = arg[1]\n",
    "\n",
    "gdf_flood = gdf_flood.set_crs(4326)\n",
    "grid_gdf = grid_gdf.set_crs(3395)\n",
    "\n",
    "gdf_flood = gdf_flood.to_crs(3395)\n",
    "\n",
    "joined = gpd.sjoin(grid_gdf, gdf_flood, how='left', predicate='contains')\n",
    "\n",
    "grid_gdf['average_value'] = joined.groupby(joined.index)['value'].mean()\n",
    "\n",
    "grid_gdf = grid_gdf[[\"geometry\", \"average_value\"]]\n",
    "grid_gdf = grid_gdf.rename(columns={\"average_value\": \"value\"})\n",
    "\n",
    "grid_gdf = grid_gdf.dropna(subset=[\"value\"])\n",
    "\n",
    "grid_gdf.metadata = {\n",
    "    'name': 'ground'\n",
    "}\n",
    "\n",
    "return grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge (grid_gdf, gdf_buildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation analysis\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "grid_gdf = arg[0]\n",
    "gdf_buildings = arg[1]\n",
    "\n",
    "grid_gdf = grid_gdf.set_crs(3395)\n",
    "gdf_buildings = gdf_buildings.set_crs(4326)\n",
    "gdf_buildings = gdf_buildings.to_crs(3395)\n",
    "\n",
    "joined = gpd.sjoin(gdf_buildings, grid_gdf, how='left', predicate='intersects')\n",
    "\n",
    "gdf_buildings['thematic'] = joined.groupby(joined.index)['value'].mean()\n",
    "\n",
    "gdf_buildings[\"thematic\"] = gdf_buildings[\"thematic\"].fillna(0.1)\n",
    "\n",
    "gdf_buildings.metadata = {\n",
    " 'name': 'buildings'\n",
    "}\n",
    "\n",
    "return gdf_buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge (grid_gdf, gdf_buildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTK\n",
    "\n",
    "# interpolateViridis\n",
    "# \"color_map\": \"interpolateBlues\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curio-sandbox-frontend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
